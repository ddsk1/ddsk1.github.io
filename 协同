
HeCoFuse: 跨模态互补的异构传感器V2X协同感知框架详解

融合统一框架支持九种异构传感器配置（LC+LC, L+L, C+C, L+C等），动态融合互补信息。
通道注意力：
动态加权不同模态特征通道（如LiDAR通道侧重距离，相机通道侧重外观）。
空间注意力：
针对区域可靠性分配权重（如LiDAR主导远距离区域，相机主导视觉复杂区域）。
配置感知下采样：
根据传感器类型调整特征图分辨率（相机节点高分辨率，LiDAR节点低分辨率）。
融合后上采样：
保留最精确传感器信息，平衡计算效率与信息保真度。

V2X-R: Cooperative LiDAR-4D Radar Fusion with Denoising Diffusion for 3D Object Detection 论文详细总结

合作LiDAR-4D雷达融合管道：
提出四阶段融合框架（编码、智能体融合、模态融合、框预测），支持多种融合策略。
多模态去噪扩散（MDD）模块：
利用4D雷达的天气鲁棒特征引导扩散模型去噪LiDAR特征，提升恶劣天气下的检测性能。


STAMP: SCALABLE TASK- AND MODEL-AGNOSTIC COLLABORATIVE PERCEPTION 论文详细总结
提出首个可扩展、任务和模型无关的协作感知框架，解决异构智能体的三大差异（模态、模型架构、任务目标）。


POINT CLUSTER: A COMPACT MESSAGE UNIT FOR COMMUNICATION-EFFICIENT COLLABORATIVE PERCEPTION 论文详细总结
点簇定义：
将潜在对象表示为包含点坐标（结构）、聚类中心（位置）和高维特征（语义）的稀疏单元。
优势对比BEV：
1.
稀疏性：仅包含前景对象，减少冗余。
2.
结构保留：显式保留3D几何信息，提升边界精度。
3.
高效聚合：基于对象匹配，复杂度与对象数量相关（而非感知范围平方） 。

UniV2X: 端到端V2X协同自动驾驶框架详解

BEV特征提取：
使用BEVFormer将图像转换为鸟瞰图特征，TrackFormer与MapFormer分别提取车辆与车道查询，OccFormer生成占据概率图。
数据传输优化：
车辆查询与车道查询通过流预测模块补偿通信延迟。
占据概率图通过线性操作压缩时间维度（仅需传输初始与变化量）。
跨视图融合：
Agent融合：时空同步、旋转感知查询变换、匈牙利匹配与融合。
车道融合：类似Agent融合，但忽略时间同步（车道静态）。
占据预测融合：基于相对位姿转换概率图，融合后生成二值占据图。
规划输出：
结合融合后的查询、车道与占据图，生成未来航点，并通过成本函数避免碰撞。
